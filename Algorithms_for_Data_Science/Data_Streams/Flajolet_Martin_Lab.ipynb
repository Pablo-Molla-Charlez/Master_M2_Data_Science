{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpOHLyhPpaxC"
   },
   "source": [
    "# Algorithms for Data Science -- Laboratory 4\n",
    "Author: Pablo Mollá Chárlez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvZ7rLY2pg8i"
   },
   "source": [
    "# Counting Distinct Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flajolet-Martin (FM) algorithm is a $\\textcolor{green}{\\text{probabilistic algorithm}}$ $\\textcolor{green}{\\text{used for estimating}}$ $\\textcolor{green}{\\text{the number of distinct elements}}$ $\\textcolor{green}{\\text{(cardinality) in a large data stream}}$, especially when storing all the data is impractical due to space limitations. It provides a memory-efficient way to estimate the count of distinct items in streaming data, which makes it ideal for applications like web analytics, network traffic monitoring, and database systems.\n",
    "\n",
    "- $\\textcolor{red}{\\text{Why not count the distinct items directly?}}$\n",
    "\n",
    "    For large datasets, counting distinct elements exactly requires either storing the entire dataset or using a large amount of memory. This is inefficient when the dataset is huge, or when you're dealing with continuous streams of data that you cannot store entirely. Instead, Flajolet-Martin leverages hash functions and bit patterns to estimate the count using much less memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example: Single Hash Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple example to understand the main idea of the **Flajolet-Martin approach**.\n",
    "\n",
    "Let's say we have a small **data stream** of 4 distinct items:\n",
    "$$\n",
    "\\textcolor{green}{Items} \\text{: ['apple', 'banana', 'orange', 'apple', 'grape', 'banana']}\n",
    "$$\n",
    "\n",
    "Our $\\textcolor{orange}{\\text{goal is to estimate the number of distinct items}}$, which in this case are $apple$, $banana$, $orange$, and $grape$, so the true distinct count is 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: $\\fbox{Hash the Items}$\n",
    "\n",
    "We apply a hash function to each item. For simplicity, let's pretend we hash the items to these numbers (in binary):\n",
    "$$\n",
    "\\text{hash('apple')}  = 101000 ( 40 \\text{ in decimal}) \\\\\n",
    "\\text{hash('banana')} = 1100000 ( 96 \\text{ in decimal}) \\\\\n",
    "\\text{hash('orange')} = 10000 ( 16 \\text{ in decimal}) \\\\\n",
    "\\text{hash('grape')} = 101000 ( 40 \\text{ in decimal}) \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: $\\fbox{Count Trailing Zeros}$\n",
    "\n",
    "Next, we $\\textcolor{orange}{\\text{count the number of trailing zeros}}$ (the trailing zeros are a sequence of 0 in the decimal representation of a number, after which no other digits follow) in each binary hash:\n",
    "\n",
    "- $\\text{hash('apple')}$ = 101000 has **3 trailing zeros**.\n",
    "- $\\text{hash('banana')}$ = 1100000 has **5 trailing zeros**.\n",
    "- $\\text{hash('orange')}$ = 10000 has **4 trailing zeros**.\n",
    "- $\\text{hash('grape')}$ = 101000 (same as 'apple') has **3 trailing zeros**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: $\\fbox{Track the Maximum Trailing Zeros}$\n",
    "\n",
    "We $\\textcolor{orange}{\\text{keep track of the maximum number of trailing zeros}}$ across all hashed values:\n",
    "- $\\textcolor{green}{\\text{Maximum number of trailing zeros}}$ = $\\textcolor{green}{5}$ (from $'banana'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: **Estimate the Distinct Count**\n",
    "\n",
    "The Flajolet-Martin algorithm estimates the number of distinct items as:\n",
    "$$\n",
    "\\text{Estimate} = 2^{\\text{Max Trailing Zeros}} = 2^5 = 32\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "In this example, the algorithm **overestimates** the number of distinct items because we only had 4 distinct items. The estimate is 32, which shows that with a small number of hash functions or items, the algorithm can be imprecise. But as the stream size grows and with multiple hash functions, the estimate becomes much more accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined Example: Multiple Random Hash Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say $\\textcolor{green}{\\text{we have 5 hash functions}}$, and for each one, the maximum number of trailing zeros (out of 1000 hashed values from the stream) is as follows:\n",
    "\n",
    "- $h1$ = 10 trailing zeros\n",
    "- $h2$ = 9 trailing zeros\n",
    "- $h3$ = 11 trailing zeros\n",
    "- $h4$ = 12 trailing zeros\n",
    "- $h5$ = 9 trailing zeros\n",
    "\n",
    "### $\\fbox{1. Average of the Estimators}$\n",
    "As mentioned, the first estimation using the $\\textcolor{green}{\\text{average}}$ is:\n",
    "\n",
    "$$\n",
    "\\text{Average estimation} = \\frac{2^{10} + 2^{9} + 2^{11} + 2^{12} + 2^{9}}{5}\n",
    "= \\frac{1024 + 512 + 2048 + 4096 + 512}{5}\n",
    "= \\frac{8192}{5} = 1638.4\n",
    "$$\n",
    "\n",
    "### $\\fbox{2. Median of the Estimators}$\n",
    "For the $\\textcolor{purple}{\\text{median}}$ method, we take the powers of 2 for each trailing zero count and then find the median of those values:\n",
    "\n",
    "The estimations based on trailing zeros:\n",
    "- $h1$ = \\(2^{10} = 1024\\)\n",
    "- $h2$ = \\(2^9 = 512\\)\n",
    "- $h3$ = \\(2^{11} = 2048\\)\n",
    "- $h4$ = \\(2^{12} = 4096\\)\n",
    "- $h5$ = \\(2^9 = 512\\)\n",
    "\n",
    "Now, sort these estimations:\n",
    "$$\n",
    "[512, 512, 1024, 2048, 4096]\n",
    "$$\n",
    "\n",
    "The $\\textcolor{purple}{\\text{median}}$ value is the middle one, which is 1024. \n",
    "\n",
    "### $\\fbox{3. Group median method}$:\n",
    "\n",
    "For the $\\textcolor{orange}{\\text{group median method}}$, let's divide the 5 estimators into groups. Since 5 is a small number, we can group them into two groups:\n",
    "- Group 1: $2^{10} = 1024$, $2^{9} = 512$, $2^{11} = 2048$\n",
    "- Group 2: $2^{12} = 4096$, $2^{9} = 512$\n",
    "\n",
    "Now, $\\textcolor{orange}{\\text{compute the median}}$ of each group:\n",
    "- Median of Group 1: $[512, 1024, 2048]$ $\\Longrightarrow$ **1024**.\n",
    "- Median of Group 2: $[512, 4096]$ $\\Longrightarrow$ $\\frac{512+4096}{2} = \\frac{4608}{2} = $**2048**.\n",
    "\n",
    "Finally, we take the $\\textcolor{orange}{\\text{average** of these two medians}}$:\n",
    "$$\n",
    "\\text{Group median average} = \\frac{1024 + 2048}{2} = 1536\n",
    "$$\n",
    "\n",
    "### Summary of Estimates:\n",
    "- **Average estimation**: $1638.4$\n",
    "- **Median estimation**: $1024$\n",
    "- **Group median average**: $1536$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqIyJ2BgplVA"
   },
   "source": [
    "## 1. Preliminaries \n",
    "\n",
    "The objective of this lab is to implement the Flajolet-Martin approach to count distinct items. First, we generate an universe of $N$ strings of length $12$, and take $d$ items which will constitute our universe of distinct items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "uj1GxrPF_DxQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mtfsdkgpdbpf', 'mxiufjqqswlc', 'puydmimtohdz']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from string import ascii_lowercase\n",
    "\n",
    "# Parameters\n",
    "# Universe of N \n",
    "N = 256\n",
    "# Distinct items\n",
    "d = 3 \n",
    "# size of stream\n",
    "stream_size = 10000\n",
    "\n",
    "# Generate some random strings of size 10\n",
    "U = []\n",
    "for _ in range(N):\n",
    "  U.append(''.join(random.choice(ascii_lowercase) for i in range(12)))\n",
    "\n",
    "D = random.sample(U,k=d)\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgKzrJj3_oiX"
   },
   "source": [
    "## 2. Flajolet-Martin: Creating a Hash Function, Estimating Distinct Items Using Trailing 0s\n",
    "\n",
    "In the following we create a hash function $h(x)$, which also takes as a parameter a hashable and $N$, and returns a value in the range $\\{0, \\dots, N-1 \\}$. \n",
    "\n",
    "We simulate a stream taking random values from $D$, count the trailing $0$s in its hash value, keep the maximum value $R$, and then output $2^R$ as the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "IbQ0B1a3BpAV",
    "outputId": "b5f8e92e-b215-4b12-9691-aa5310c29145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of distinct items: 2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "random.seed(datetime.now().timestamp())\n",
    "\n",
    "def h(x,n):\n",
    "  return hash(x)%n\n",
    "\n",
    "# Method for counting trailing 0s\n",
    "def trailing_0(x):\n",
    "  x1 = x\n",
    "  t0 = 0\n",
    "  while x1%2==0 and x1!=0:\n",
    "    t0 += 1\n",
    "    x1 = int(x1/2)\n",
    "  return t0\n",
    "\n",
    "# Simulating the stream\n",
    "R = 0\n",
    "for _ in range(stream_size):\n",
    "  # Take a random string from the distinct pool\n",
    "  s = random.choice(D)\n",
    "  # Check its hash value\n",
    "  # To allow more space for hash values\n",
    "  hv = h(s,2*N)\n",
    "  r = trailing_0(hv)\n",
    "  if r>R: R=r\n",
    "\n",
    "est = int(math.pow(2,R))\n",
    "\n",
    "print('Estimation of distinct items: %d'%est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz9rNT2Na35t"
   },
   "source": [
    "## 3. **TASK** Flajolet-Martin: Using Multiple Hash Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textcolor{red}{\\text{Implement the refined version of the above estimator}}$, using multiple ($k$) hash functions (use the method of generating several pairs of numbers presented last time in the lab) and compute:\n",
    "\n",
    "1. The $\\textcolor{purple}{\\text{average of the k estimators}}$.\n",
    "\n",
    "2. The $\\textcolor{purple}{\\text{median of the k estimators}}$.\n",
    "\n",
    "3. $\\textcolor{purple}{\\text{Divide the estimators into groups}}$ (vary the group size); $\\textcolor{purple}{\\text{take the median in each group}}$ and then the $\\textcolor{purple}{\\text{average over the groups}}$.\n",
    "\n",
    "$\\textcolor{red}{\\text{Compare the three method's final outputs}}$. $\\textcolor{orange}{\\text{What do you notice?}}$\n",
    "\n",
    "$\\fbox{Note}$: You can use the Python 3.4 '_statistics_' package (not available in previous versions) to compute medians, averages, and other statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Parameters & Universe U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3Va-_6fda-jf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universe U (256): ['bfeetacddter', 'dvwoyezcufrb', 'gesdghaukxht', 'pgvvpkjckwrl', 'ysfuvoifnjus', 'bdfjbiiwmcej', 'xkbivyxfpavc', 'mdldfsabdmza', 'vshapnitsfcb', 'idjmtrqdqose', 'hiqyskjcoakr', 'ptdehyfscrup', 'cihagvlgbfrw', 'myzagcocdjcb', 'vmhmkghecbjz', 'gcnypvewwaoe', 'rsrdalepycig', 'dzmwpeuyucny', 'pbzlkfrcoqvi', 'npvnbwntajyz', 'yvstffcshyqh', 'syjvtvlirjvd', 'bivlgmmaxydh', 'yghbkaqcbbfe', 'tjblaqkrehxw', 'xyhtbqgxyvfy', 'dboflzoqrzsm', 'dioryfbhpvcb', 'fqxhbsejwoav', 'eoipyiarsfws', 'useuftggymtg', 'dxuspgngxlvl', 'oszpdogfbeiq', 'uctjgiikpzmi', 'xxdskwklzzog', 'hssrefjcelmz', 'rsfhuhsuzjhi', 'itffmwswmdxq', 'jepslevsrdhc', 'piojdoflodhe', 'nhronotacoun', 'batgbmvaxftk', 'nzghbpavumgd', 'dcwbylshvzxd', 'bovahxmiqawl', 'blnjyfprawbf', 'ulusniyiysou', 'bultonhbjwnz', 'njsvwjauuvsh', 'ptgjanlvjxdq', 'xjomirsximqi', 'ingwpfwiuraj', 'qysnksktkdwg', 'hdwknlvrecof', 'yctsxtovznop', 'smlgbrfgkexy', 'vccbpbxwnjco', 'rdribyemlvwk', 'ehhifljkbxlg', 'rbybsgadllok', 'opqpexcxzpuf', 'eehzjzmjqlfw', 'jhbkwpxkqcvw', 'qbdzsvpjceca', 'izxfrdlqhraa', 'ynehptnrfemz', 'ildchcjhzkkq', 'usrribyoyqlg', 'vxfihrxfaela', 'zofeehgejvvk', 'bmsgosorzrvo', 'flpiznvvfrzw', 'iosnklpfctgr', 'balnbjqmnqui', 'pxtdwkxdztti', 'rzakejryjegg', 'fhxmwolwhnok', 'rajrdhrydxio', 'nzwamowvzyyf', 'yyifseaudvhc', 'anwrljyqepol', 'bkuhbzgewmwf', 'kisfvujksgur', 'gfqfwseibzxu', 'wuhjmhkkuhgk', 'kixiygmfaiwb', 'ruwdvmzrkwtm', 'wgnebpnnxhlc', 'ixghriavhptc', 'bmjzspkexhcg', 'ojpyjamwrbpb', 'nkecsbijidao', 'bymqbnasypjw', 'insziupbfewp', 'nlptvyjumify', 'ldolufpczoot', 'eneupbkmiqev', 'hlapqapfbwry', 'qlyfcrwyxptk', 'povudwemcbyo', 'rtxjjirkqieq', 'kfdmvjtjnzuy', 'cockdmhjreop', 'duneytujhahz', 'unpoxgsfezzz', 'zankepdkgowf', 'otaaqmonyfxy', 'hcedbwbyquqk', 'sixqefhkvjeb', 'xfpnzjoubukf', 'adrfjnxvmeuy', 'nwrlbvczufcm', 'duytniynrtnh', 'ptmadqjzkaqa', 'hebloctbjrts', 'zkvuqnsojlur', 'iopyvmxpifpq', 'ysbzvoxhuvhk', 'wifbnwodahxl', 'gkwdjxeryulf', 'tautfqtwvvld', 'uvewctvwcgdl', 'bnopjrpxcxfd', 'czzxckdojcvm', 'xevuezbjvpoi', 'azpiopdgssbk', 'hafcoufumwmf', 'lttqzvrkexsb', 'hpvcomekffps', 'hlykrzfmwhjc', 'yotmpwpkucac', 'raoieqjckspt', 'ijqhwagnvgih', 'vtmortpulyrq', 'bvwjcqcgliqn', 'dynrmpqyokan', 'owhkywdjckhk', 'vbfkwvcbebyq', 'hmcntpewyfuk', 'oribfkhejwdc', 'thmrnetyusli', 'dbkespmqhgtm', 'scsymqrwgxcz', 'etnbejpukuib', 'aaiftuusjtxj', 'ghupzmegymxs', 'xvatvmdgbvyj', 'nfowlxqrxthn', 'fsnwvdbrdjyi', 'slqjhyumgwkh', 'ixgxjmiiojee', 'gpmigqqbkemu', 'rhbgcdgwkzgw', 'xebeeraidshi', 'oxaxktbhkivr', 'rswilcnnzdal', 'pzamgngyubgo', 'hzsawjwwlkhf', 'zrtmavmzsian', 'lxnckslbygry', 'zfgahqovkkaw', 'xoarvtihibsx', 'apdnwhsihlsf', 'hhevpvotjjzu', 'ksltexocrzlt', 'skgyfhjdpiff', 'hpxtzgyqmazv', 'yhjaiisrwocz', 'dxeifybezppl', 'kyryyctumuft', 'xveklewpcgrt', 'omljexatpcdh', 'oapahojhvpsq', 'kwdpoctczamc', 'quduxhrxqwmf', 'kqtztulvsqus', 'kitejuzcdmth', 'ioilzclanbim', 'yrxvkmsrcsee', 'ptnzduvzzbbv', 'yumckykedekb', 'kkjothgwgblg', 'setohojtckwr', 'brntlcbuibso', 'vmofchpdgcdr', 'gllfxufpcrip', 'jquxexxmjsnt', 'eyulrrseogem', 'xngqwfwkgxmp', 'wlyfibgnibeb', 'ynyzxfzgdrfq', 'tcjlnmmkqmjv', 'joejdpglhxou', 'ffkcxsrvwrhh', 'lijxlfrirhxk', 'iimnpversxor', 'duzzlobvvzja', 'hnvgcghnqgrt', 'lrpgtkbgfewb', 'dcqttwyocpkg', 'kgwgyvyfbjnj', 'sklzetyizceb', 'ajalawpbiqrh', 'pvlvjddozoab', 'btdgnrnmgxtf', 'qldgrhhwzjnt', 'fguugovdcbcb', 'jmsdokpsfxhg', 'rnsnpeeaienw', 'stskudzbapmg', 'dfgdnairkjxk', 'tbnmrjejozpx', 'mgxxelkeozbv', 'bpqapyfieakm', 'mjmvjtjrhxyo', 'edrnymlygafr', 'wcmbltyvoeny', 'enmvvekhxcdp', 'nabargriruwc', 'vxtxftrvpxxf', 'kwsugardfqlo', 'lvojescvlsyy', 'vdtgpgpjhgzq', 'yzmarvsbcluk', 'jykjjyvgvgzo', 'dbjbguizdzsa', 'uikjuldvugch', 'cfaucetqiwhh', 'hzzwvtnhxulq', 'xuvwlebcktsu', 'eybmqjqmicdk', 'jfvlrqeiprsh', 'etbplyobcexv', 'tkhmdhexrpby', 'oaikiygnoxox', 'iyikafipybby', 'imonitffxeez', 'fhavkfnmwsqs', 'helvamupvnwv', 'cqxyuoeitcro', 'dcqqrfjmbifg', 'gyctlnngnzvo', 'lapxkkrylpgm', 'igcysvrrawcc', 'wtotyjsklflv', 'kubwdqtovkne', 'rkbjomrdfwwl', 'wawcgkcimosl', 'axdggkwsxozq', 'ilidstpxrgkb', 'krpcskjzeyzb', 'mfzbcqpefpmf', 'pasnjivrhjdt', 'qnkbuxahcvbv', 'iojotkweldep', 'giftaeuuvxzw']\n",
      "Distinct Items (3): ['vdtgpgpjhgzq', 'etnbejpukuib', 'mdldfsabdmza']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "import statistics\n",
    "\n",
    "# Parameters\n",
    "N = 256  # Universe size\n",
    "d = 3  # Number of distinct items\n",
    "stream_size = 10000  # Size of stream\n",
    "k = 5  # Number of hash functions\n",
    "group_size = 3  # Group size for group median method\n",
    "p = 1223543677  # Large prime number for the hash function\n",
    "\n",
    "# Generating universe U and distinct items D\n",
    "U = [''.join(random.choice(ascii_lowercase) for i in range(12)) for _ in range(N)]\n",
    "D = random.sample(U, k=d)\n",
    "\n",
    "print(f\"Universe U ({N}):\", U)\n",
    "print(f\"Distinct Items ({d}):\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Hash Functions with random pairs (a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash function that takes random a, b, p, and universe size n\n",
    "def h(x, a, b, p, n):\n",
    "    return ((a * hash(x) + b) % p) % n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Flajolet-Martin Estimator with multiple hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flajolet-Martin estimator with multiple hash functions\n",
    "def flajolet_martin(D, k, stream_size, N, p):\n",
    "    # Randomly generate k pairs (a, b) for the k hash functions\n",
    "    hash_functions = [(random.randrange(p), random.randrange(p)) for _ in range(k)]\n",
    "    \n",
    "    estimators = []\n",
    "    \n",
    "    for a, b in hash_functions:\n",
    "        R = 0\n",
    "        for _ in range(stream_size):\n",
    "            x = random.choice(D)\n",
    "            hash_value = h(x, a, b, p, 2 * N)\n",
    "            r = trailing_0(hash_value)\n",
    "            if r > R:\n",
    "                R = r\n",
    "        estimators.append(int(math.pow(2, R)))\n",
    "    \n",
    "    return estimators\n",
    "\n",
    "# Running the Flajolet-Martin algorithm\n",
    "estimators = flajolet_martin(D, k, stream_size, N, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Average of the Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply computes the mean of all the estimators from each hash function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of the Estimators: 6.6\n"
     ]
    }
   ],
   "source": [
    "# 1. Average of the estimators\n",
    "avg_estimator = sum(estimators) / len(estimators)\n",
    "\n",
    "print(\"Average of the Estimators:\", avg_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Median of the Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the median of the estimators, which can provide a more robust estimate, especially when some estimators are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of the Estimators: 4\n"
     ]
    }
   ],
   "source": [
    "# 2. Median of the estimators\n",
    "median_estimator = statistics.median(estimators)\n",
    "\n",
    "print(\"Median of the Estimators:\", median_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Group Median Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the estimators into groups of size group_size, computes the median within each group, and then averages these medians to get the final estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups: [[16, 4, 1], [4, 8]]\n",
      "Medians of each group: [4, 6.0]\n"
     ]
    }
   ],
   "source": [
    "# 3. Group median method: divide into groups, compute median of each group, and average them\n",
    "def group_median(estimators, group_size):\n",
    "    groups = [estimators[i:i + group_size] for i in range(0, len(estimators), group_size)]\n",
    "    print(\"Groups:\", groups)\n",
    "    medians = [statistics.median(group) for group in groups]\n",
    "    print(\"Medians of each group:\", medians)\n",
    "    return sum(medians) / len(medians)\n",
    "\n",
    "group_median_estimator = group_median(estimators, group_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Comparison of Methods}$:\n",
    "\n",
    "- The average method can be affected by outliers, as extreme estimators could skew the result.\n",
    "\n",
    "- The median method tends to give a more robust estimate by ignoring the outliers and focusing on the central tendency of the estimators.\n",
    "\n",
    "- The group median method provides another level of robustness by taking the median of groups first and then averaging them, which can smooth out the effect of noisy hash functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators from each hash function: [16, 4, 1, 4, 8]\n",
      "Average of estimators: 6.6\n",
      "Median of estimators: 4\n",
      "Group median estimator: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(\"Estimators from each hash function:\", estimators)\n",
    "print(f\"Average of estimators: {avg_estimator}\")\n",
    "print(f\"Median of estimators: {median_estimator}\")\n",
    "print(f\"Group median estimator: {group_median_estimator}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m2_ds_algods_lab3_distinct.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
